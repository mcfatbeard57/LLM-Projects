# Fine-tuning LLaMA2 with QLoRA: Chatbot Performance and Efficiency

## Project Summary:

### Feature Description
- **Goal:** Fine-tune LLaMA2, a collection of large language models (LLMs), using the efficient QLoRA technique for enhanced chatbot performance and accessibility.
- **LLaMA2 Models:** 7B to 70B parameters, optimized for chat applications.
- **QLoRA:** Efficient fine-tuning with 4-bit precision, reducing memory usage significantly.
- **Performance:** Achieves state-of-the-art chatbot performance on benchmarks.
- **Open-Source:** All models, code, and resources are readily available.

**Train loss decreases with just 3 epochs and rank = 64** (See Below)
![image](https://github.com/mcfatbeard57/FineTuneLLama2/assets/62231146/adf07522-d766-4638-b97f-c1dbc96fe570)

## Benefits:

- **Accessibility:** Fine-tune large LLMs on smaller hardware with QLoRA.
- **Performance:** Achieve competitive chatbot performance with efficient fine-tuning.
- **Openness:** Contribute to the project and its development.

## Getting Started:

- **Read:** [Hugging Face blog post](https://huggingface.co/docs/transformers/main/en/model_doc/llama2)
- **Explore:** [LLaMA 2 resources]([Link to LLaMA 2 resources](https://huggingface.co/docs/transformers/main/en/model_doc/llama2))
- **Try:**
  - Fine-tune LLaMA2 with QLoRA: [https://github.com/artidoro/qlora]
  - Deploy LLaMA2 on Amazon SageMaker: [(https://aws.amazon.com/blogs/machine-learning/package-and-deploy-classical-ml-and-llms-easily-with-amazon-sagemaker-part-2-interactive-user-experiences-in-sagemaker-studio/)]
