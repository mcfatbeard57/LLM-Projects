# AI-arXiv-research-assistant-using-Ollama



<img width="1526" alt="QnA with ArXiv" src="https://github.com/user-attachments/assets/137b06f9-debc-4b09-bab4-96e0dc494ec0">


This file describes the code for a Gradio interface that allows users to search for arXiv papers and then ask questions about them.

**Functionality**

The application performs the following steps:

1. Takes a search query and a question as user input.
2. Downloads a maximum of 4 relevant papers from arXiv.
3. Processes the downloaded papers and extracts the full text.
4. Embeds the text using a pre-trained model (currently `sentence-transformers/all-MiniLM-L6-v2`).
5. Creates a temporary vector store using Qdrant to index the paper embeddings.
6. Uses a large language model (currently "gemma2:2b") to answer the user's question based on the retrieved papers.
7. Returns the answer generated by the large language model.

**Dependencies**

* gradio
* os
* time
* arxiv
* langchain_community (vectorstores, document_loaders, chat_models)
* langchain (prompts, pydantic_v1, schema, text_splitter)
* langchain_community (embeddings) (optional, for using GPT4AllEmbeddings)
* huggingface_transformers

**Running the Application**

1. Install the required dependencies: `pip install -r requirements.txt` (assuming you have a `requirements.txt` file listing the dependencies).
2. Run the script: `python app.py` (replace `app.py` with the actual filename if different).
3. The Gradio interface will launch in your web browser, typically at http://127.0.0.1:8080.

**Notes**

* The downloaded papers are stored in a temporary directory (`arxiv_papers`). This directory is deleted when the script finishes execution.
* The script uses a pre-defined large language model ("gemma2:2b"). This model name might need to be adjusted depending on your specific environment and available models.
* The script currently uses `sentence-transformers/all-MiniLM-L6-v2` for text embedding. This can be changed to a different model by modifying the `embedding_model` variable.

**Additional Considerations**

* Error handling: The script includes basic error handling for download failures and file loading issues. You might want to consider expanding the error handling for a more robust user experience.
* Configurability: Currently, the script uses hardcoded values for the maximum number of papers to download and the text chunking size. These parameters could be made configurable for more flexibility.
* Scalability: Downloading and processing a large number of papers might become inefficient. Consider exploring alternative approaches for handling larger datasets.
